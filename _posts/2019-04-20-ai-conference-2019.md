---
layout: post
title: "AI Conference 2019"
date: 2019-03-20
---

Recently I had the opportunity to attend [O'Reilly's AI Conference](https://conferences.oreilly.com/artificial-intelligence/ai-ny) in New York and wanted to share a bit of what the experience was like.

## Overview
The conference was scheduled for four days - the first two for hands-on workshops and the last two for talks and keynotes. There were also a few opportunities to network (speed networking), checkout vendors in the exhibit hall and meet people over dinner. The conference was smaller (in terms of attendees) than I expected but honestly that turned out to be great. When you realize that something like Amazon re:invent has around 40,000 attendees, you quickly come to the conclusion that means waiting to even get into a talk for at least an hour, let alone being able to ask the speaker a few questions afterwards. Suddenly 1000 to 5000 attendees seems quite nice.
One complaint I heard a couple times was that the tutorials weren't technical enough - I'm not sure if people were expecting to actually run through code or were wanting more mathematical theory. It's difficult to actually run the code due to the time it takes to train useful models, although perhaps there's a 3rd party vendor that could have helped with this. Re: the math - I can somewhat agree but this would require a track of talks that can fit the concepts and theoretical math into a 40 minute presentation. Doable but not for every attendee IMO.    

## Hot Topics
The two big takeaways from the talks were Deep Learning models for natural language processing and handling time series data. Most of the current models for NLP are based on recent ideas for embedding word contexts and using convolutional or recurrent neural networks:

### Deep Learning for NLP

1. ELMo 

2. ULMFiT

3. GPT-2 

4. BERT


### Handling Time Series Data

One of the most interesting talks was by Alibaba discussing their time series data processing system. Apparently they've constructed a system at scale capable of indexing and retrieving time series data but also abstracting the data to enable performing relational and linear algebra operations within the database. I'm trying to find the speaker's slide deck so I can look into this more.


## UnSurprises

One of the open questions for AI/ML is privacy and security. It was mentioned that researchers have shown it is possible to get some personally identifiable information (PII) out of a trained model. Additionally, there are some concerns about how to make a model resililient to attacks (random manipulation of the training data and/or hyperparameters to affect prediction. One of the speakers talked about the emergine field of AI security. In a world where all this data is stored in the cloud and processed in the cloud, how do you make sure it's secure? One of the ways mentioned was by encrypting the hyperparamter updates between compute nodes. A somewhat related problem of DeepFakes also came up for discussion. DeepFakes are AI generated images, video or audio that is very difficult to distinguish as fake like the DeepFake Obama videos.


## Surprises
1. Brain interfaces are coming along, esp. ones which don't require skull surgery. CTRL-Labs is developing a kit to read electrical signals from the muscles in our extremities rather than the brain.
